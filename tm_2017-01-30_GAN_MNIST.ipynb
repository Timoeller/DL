{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape:  (60000, 28, 28)\n",
      "Training input shape reshaped:  (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# code taken and refined from: https://github.com/osh/KerasGAN\n",
    "# check out https://github.com/soumith/ganhacks for tips tricks on training gans\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from IPython import display\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Training input shape: \", X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1) #tf ordering, depth/channels at last index\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train -= 127.5\n",
    "X_train /= 127.5\n",
    "X_test -= 127.5\n",
    "X_test /= 127.5 # scaling to [-1,1] matching tanh output of generator\n",
    "\n",
    "print(\"Training input shape reshaped: \",X_train.shape)\n",
    "#labels_train = to_categorical(y_train)\n",
    "#labels_test = to_categorical(y_test)\n",
    "#print(\"Training labels reshaped: \", labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "# def make_trainable(net,  val):\n",
    "#     net.trainable = val\n",
    "#     for l in net.layers:\n",
    "#         l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generative model\n",
    "\n",
    "nch = 200\n",
    "\n",
    "g_opt = Adam(lr=2e-4,beta_1=0.5)\n",
    "g_inp = Input(shape=(100,))\n",
    "\n",
    "H = Dense(nch*14*14,init='glorot_normal',input_shape=(100,))(g_inp)\n",
    "H = LeakyReLU(alpha=0.2)(H)\n",
    "H = Reshape((14,14,nch))(H)\n",
    "H = BatchNormalization(mode=2,axis=-1)(H) # if using theano change axis argument here!!!\n",
    "H = UpSampling2D(size=(2,2))(H)\n",
    "H = Convolution2D(int(nch/2),3,3,border_mode='same',init='glorot_normal')(H)\n",
    "H = BatchNormalization(mode=2,axis=-1)(H)\n",
    "H = LeakyReLU(alpha=0.2)(H)\n",
    "H = Dropout(0.25)(H)\n",
    "H = Convolution2D(int(nch/4),3,3,border_mode='same',init='glorot_normal')(H)\n",
    "H = BatchNormalization(mode=2)(H)\n",
    "H = LeakyReLU(alpha=0.2)(H)\n",
    "H = Dropout(0.25)(H)\n",
    "\n",
    "#H = Convolution2D(1, 1, 1, border_mode='same', init='glorot_uniform')(H)\n",
    "#g_pred = Activation('sigmoid')(H)\n",
    "g_pred = Dense(1,init='glorot_normal',activation='tanh')(H)\n",
    "\n",
    "generator = Model(g_inp,g_pred)\n",
    "generator.compile(loss='binary_crossentropy',optimizer=g_opt)\n",
    "#generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# discriminator\n",
    "d_opt = Adam(lr=2e-4,beta_1=0.5)\n",
    "d_inp = Input(shape=X_train.shape[1:])\n",
    "\n",
    "H = Convolution2D(256,5,5,subsample=(2,2),border_mode='same',\n",
    "                  init='glorot_normal',input_shape=X_train.shape[1:])(d_inp)\n",
    "#H = BatchNormalization(mode=2,axis=-1)(H)\n",
    "H = LeakyReLU(alpha=0.2)(H)\n",
    "#H = AveragePooling2D(pool_size=(2,2))(H)\n",
    "H = Dropout(0.25)(H)\n",
    "\n",
    "H = Convolution2D(512,5,5,subsample=(2,2),border_mode='same',init='glorot_normal')(H)\n",
    "#H = BatchNormalization(mode=2,axis=-1)(H)\n",
    "H = LeakyReLU(alpha=0.2)(H)\n",
    "#H = AveragePooling2D(pool_size=(2,2))(H)\n",
    "H = Dropout(0.25)(H)\n",
    "\n",
    "H = Flatten()(H)\n",
    "H = Dense(256)(H)\n",
    "#H = BatchNormalization(mode=2,axis=-1)(H) # without BN here BN in prev layers makes train impossible\n",
    "H = LeakyReLU(alpha=0.2)(H)\n",
    "H = Dropout(0.25)(H)\n",
    "d_pred = Dense(1,activation='sigmoid')(H)\n",
    "\n",
    "discriminator = Model(d_inp,d_pred)\n",
    "discriminator.compile(loss='binary_crossentropy',optimizer = d_opt)#,metrics=['accuracy'])\n",
    "#discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_5 (Model)                  (None, 28, 28, 1)     540401      input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_9 (Model)                  (None, 1)             48451       model_5[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 588,852\n",
      "Trainable params: 588,352\n",
      "Non-trainable params: 500\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN, put together\n",
    "#make_trainable(discriminator,False)\n",
    "gan_inp = Input(shape=(100,))\n",
    "H = generator(gan_inp)\n",
    "gan_pred = discriminator(H)\n",
    "GAN = Model(gan_inp,gan_pred)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer = g_opt)\n",
    "GAN.summary()\n",
    "\n",
    "# set up loss storage vector\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "\n",
    "#helper fcts\n",
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "        #plt.plot(losses[\"d\"][1], label='discriminitive acc')\n",
    "        plt.plot(losses[\"g\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def plot_gen(n_ex=16,dim=(2,8), figsize=(10,3) ):\n",
    "    noise = np.random.uniform(-1,1,size=[n_ex,100])\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,:,:,0]\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28, 28, 1) labels: (20000, 1)\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 57s - loss: 0.0022    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1074c8828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### pre train discriminator\n",
    "num_samples= 10000\n",
    "random_g_inp = np.random.normal(0,1,size=(num_samples,100))\n",
    "random_gen = generator.predict(random_g_inp)\n",
    "\n",
    "idxX = np.random.permutation(X_train.shape[0])[:num_samples]\n",
    "X = np.concatenate((X_train[idxX] ,random_gen))\n",
    "y = np.zeros((X.shape[0],1))\n",
    "y[:num_samples,0]=1\n",
    "\n",
    "idx = np.random.permutation(num_samples*2)\n",
    "print(str(X.shape) + ' labels: ' + str(y.shape))\n",
    "discriminator.fit(X[idx],y[idx],nb_epoch=1,batch_size=32)\n",
    "\n",
    "\n",
    "num_samples= 2000\n",
    "random_g_inp = np.random.normal(0,1,size=(num_samples,100))\n",
    "random_gen = generator.predict(random_g_inp)\n",
    "\n",
    "idxX = np.random.permutation(X_train.shape[0])[:num_samples]\n",
    "X = np.concatenate((X_train[idxX] ,random_gen))\n",
    "y = np.zeros((X.shape[0],1))\n",
    "y[:num_samples,0]=1.0\n",
    "\n",
    "yhat = discriminator.predict(X)\n",
    "np.sum(np.abs(y-yhat))#/(2*num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up loss storage vector\n",
    "losses = {\"d\":[], \"g\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gradients(model):\n",
    "    \"\"\"Return the gradient of every trainable weight in model\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    model : a keras model instance\n",
    "\n",
    "    First, find all tensors which are trainable in the model. Surprisingly,\n",
    "    `model.trainable_weights` will return tensors for which\n",
    "    trainable=False has been set on their layer (last time I checked), hence the extra check.\n",
    "    Next, get the gradients of the loss with respect to the weights.\n",
    "\n",
    "    \"\"\"\n",
    "    #weights = [tensor for tensor in model.trainable_weights if model.get_layer(tensor.name[:-2]).trainable]\n",
    "    weights = model.trainable_weights\n",
    "    optimizer = model.optimizer\n",
    "\n",
    "    return optimizer.get_gradients(model.total_loss, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_for_n(nb_epoch=5000, plt_frq=25,BATCH_SIZE=32):\n",
    "\n",
    "    for e in tqdm.trange(nb_epoch):  \n",
    "        \n",
    "        batch_d = BATCH_SIZE\n",
    "        # Make generative images\n",
    "        idx = np.random.randint(0,X_train.shape[0],size=int(batch_d/2))\n",
    "        image_batch = X_train[idx,:,:,:]    \n",
    "        noise_gen = np.random.normal(0,1,size=[int(batch_d/2),100])\n",
    "        generated_images = generator.predict(noise_gen)\n",
    "        \n",
    "        # Train discriminator on real images \n",
    "        discriminator.trainable = True\n",
    "        y1 = np.ones((int(batch_d/2),1)) + np.random.uniform(-0.2,0.3,size=(int(batch_d/2),1))\n",
    "        d_loss  = discriminator.train_on_batch(image_batch,y1)\n",
    "        #losses[\"d\"].append(d_loss)\n",
    "        # and on generated images\n",
    "        y12 = np.zeros((int(batch_d/2),1)) + np.random.uniform(0,0.2,size=(int(batch_d/2),1))\n",
    "        d_loss2  = discriminator.train_on_batch(generated_images,y12)\n",
    "        losses[\"d\"].append((d_loss+d_loss2)/2)\n",
    "    \n",
    "    \n",
    "        batch_g = BATCH_SIZE\n",
    "        #train generator on 2 batches\n",
    "        #discriminator.trainable(False)\n",
    "        discriminator.trainable = False\n",
    "        noise_tr = np.random.normal(0,1,size=[batch_d,100])\n",
    "        y2 = np.ones((batch_d,1))  + np.random.uniform(-0.2,0.3,size=(batch_g,1)) # generator wants to create real labels\n",
    "        g_loss = GAN.train_on_batch(noise_tr, y2)\n",
    "        losses[\"g\"].append(g_loss)\n",
    "        \n",
    "        # Updates plots\n",
    "        if e%plt_frq==plt_frq-1:\n",
    "            discriminator.trainable = True\n",
    "            gradients = get_gradients(GAN)\n",
    "            \n",
    "            print(len(gradients))\n",
    "            sess = K.get_session()\n",
    "            with sess.as_default():\n",
    "                print(gradients[0].eval())\n",
    "            \n",
    "            #plot_loss(losses)\n",
    "            #plot_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'keras_learning_phase' with dtype bool\n\t [[Node: keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: moments_3/sufficient_statistics/Shape/_195 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_moments_3/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'keras_learning_phase', defined at:\n  File \"/home/timomoeller/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/timomoeller/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5163407a782d>\", line 16, in <module>\n    H = Dropout(0.25)(H)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/layers/core.py\", line 110, in call\n    x = K.in_train_phase(dropped_inputs, lambda: x)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2207, in in_train_phase\n    if learning_phase() is 1:\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 72, in learning_phase\n    name='keras_learning_phase')\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'keras_learning_phase' with dtype bool\n\t [[Node: keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: moments_3/sufficient_statistics/Shape/_195 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_moments_3/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'keras_learning_phase' with dtype bool\n\t [[Node: keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: moments_3/sufficient_statistics/Shape/_195 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_moments_3/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b73afc0c3e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_for_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt_frq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ccb30b2fcb65>\u001b[0m in \u001b[0;36mtrain_for_n\u001b[0;34m(nb_epoch, plt_frq, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#plot_loss(losses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'keras_learning_phase' with dtype bool\n\t [[Node: keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: moments_3/sufficient_statistics/Shape/_195 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_moments_3/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'keras_learning_phase', defined at:\n  File \"/home/timomoeller/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/timomoeller/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5163407a782d>\", line 16, in <module>\n    H = Dropout(0.25)(H)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/layers/core.py\", line 110, in call\n    x = K.in_train_phase(dropped_inputs, lambda: x)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2207, in in_train_phase\n    if learning_phase() is 1:\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 72, in learning_phase\n    name='keras_learning_phase')\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'keras_learning_phase' with dtype bool\n\t [[Node: keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: moments_3/sufficient_statistics/Shape/_195 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_moments_3/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "train_for_n(nb_epoch=5, plt_frq=1, BATCH_SIZE=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_181:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d_opt.lr.assign(1e-4)\n",
    "g_opt.lr.assign(1e-4)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
