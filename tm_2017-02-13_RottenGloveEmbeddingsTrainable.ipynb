{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timomoeller/.virtualenvs/keras/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/timomoeller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "\n",
    "train_df = pd.read_csv('rotten/train.tsv', sep='\\t', header=0)\n",
    "test_df = pd.read_csv('rotten/test.tsv', sep='\\t', header=0)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection length 7096\n",
      "training corpus size 15288\n",
      "test corpus size 9588\n"
     ]
    }
   ],
   "source": [
    "# compute intersection of dictionaries\n",
    "phrases = train_df[\"Phrase\"].values\n",
    "toke = Tokenizer()\n",
    "toke.fit_on_texts(phrases)\n",
    "word_index = toke.word_index.keys()\n",
    "\n",
    "phrases = test_df[\"Phrase\"].values\n",
    "toke = Tokenizer()\n",
    "toke.fit_on_texts(phrases)\n",
    "word_index2 = toke.word_index.keys()\n",
    "\n",
    "a = word_index2 & word_index\n",
    "print(\"intersection size %i\" %len(a))\n",
    "print(\"training corpus size %i\" %len(word_index))\n",
    "print(\"test corpus size %i\" %len(word_index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15288 unique tokens.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "\n",
    "phrases = train_df[\"Phrase\"].values\n",
    "toke = Tokenizer()\n",
    "toke.fit_on_texts(phrases)\n",
    "sequences = toke.texts_to_sequences(phrases)\n",
    "word_index = toke.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_train = np_utils.to_categorical(train_df[\"Sentiment\"].values)\n",
    "X_test = pad_sequences(toke.texts_to_sequences(test_df[\"Phrase\"].values), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#load glove vectors\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = 'rotten/glove.6B'\n",
    "import os\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.%id.txt' %EMBEDDING_DIM))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "#take only word vecs that are in training dictionary\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.59900000e+04,   2.67400000e+04,   2.15490000e+04,\n",
       "          1.50330000e+04,   2.03910000e+04,   7.36200000e+03,\n",
       "          6.20900000e+03,   5.31200000e+03,   8.54000000e+03,\n",
       "          3.54800000e+03,   3.02900000e+03,   2.69600000e+03,\n",
       "          2.45500000e+03,   4.14100000e+03,   1.76200000e+03,\n",
       "          1.49000000e+03,   1.32100000e+03,   2.36600000e+03,\n",
       "          8.82000000e+02,   7.86000000e+02,   6.74000000e+02,\n",
       "          6.15000000e+02,   9.83000000e+02,   3.67000000e+02,\n",
       "          3.16000000e+02,   3.20000000e+02,   4.34000000e+02,\n",
       "          1.33000000e+02,   1.24000000e+02,   1.08000000e+02,\n",
       "          9.20000000e+01,   1.11000000e+02,   4.50000000e+01,\n",
       "          3.90000000e+01,   3.00000000e+01,   2.80000000e+01,\n",
       "          1.40000000e+01,   1.20000000e+01,   1.00000000e+01,\n",
       "          3.00000000e+00]),\n",
       " array([  0.   ,   1.225,   2.45 ,   3.675,   4.9  ,   6.125,   7.35 ,\n",
       "          8.575,   9.8  ,  11.025,  12.25 ,  13.475,  14.7  ,  15.925,\n",
       "         17.15 ,  18.375,  19.6  ,  20.825,  22.05 ,  23.275,  24.5  ,\n",
       "         25.725,  26.95 ,  28.175,  29.4  ,  30.625,  31.85 ,  33.075,\n",
       "         34.3  ,  35.525,  36.75 ,  37.975,  39.2  ,  40.425,  41.65 ,\n",
       "         42.875,  44.1  ,  45.325,  46.55 ,  47.775,  49.   ]),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4648e86d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = np.asarray([len(s) for s in sequences])\n",
    "plt.hist(lengths,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 20, 100)       1528900     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 256)           365568      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 5)             1285        lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1,895,753\n",
      "Trainable params: 1,895,753\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM with embedding trainable\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, BatchNormalization\n",
    "from keras.layers import LSTM, GRU, AveragePooling1D\n",
    "\n",
    "opt = Adam(0.004)\n",
    "inp = Input(shape=X_train.shape[1:])\n",
    "x = Embedding(len(word_index) + 1,\n",
    "              EMBEDDING_DIM,\n",
    "              weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH,\n",
    "              trainable=True,\n",
    "              input_shape=X_train.shape[1:])(inp)\n",
    "x = LSTM(256, return_sequences=False, dropout_W = 0.3, dropout_U = 0.3)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "pred = Dense(5,activation='softmax')(x)\n",
    "\n",
    "model = Model(inp,pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/3\n",
      "124848/124848 [==============================] - 41s - loss: 0.9007 - categorical_accuracy: 0.6262 - val_loss: 0.8012 - val_categorical_accuracy: 0.6683\n",
      "Epoch 2/3\n",
      "124848/124848 [==============================] - 39s - loss: 0.7459 - categorical_accuracy: 0.6875 - val_loss: 0.7810 - val_categorical_accuracy: 0.6777\n",
      "Epoch 3/3\n",
      "124848/124848 [==============================] - 39s - loss: 0.6751 - categorical_accuracy: 0.7152 - val_loss: 0.7908 - val_categorical_accuracy: 0.6755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa44812fe80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kaggle results: \n",
    "# 0.65589, glove embeddings only for words E training corpus, but trainable, 3 epochs only\n",
    "# x = LSTM(256, return_sequences=False, dropout_W = 0.3, dropout_U = 0.3)(x)\n",
    "# x = BatchNormalization()(x) + Dense 5\n",
    "\n",
    "# 0.65234 no batchnorm, plus validation split\n",
    "\n",
    "\n",
    "idx = np.random.permutation(X_train.shape[0])\n",
    "model.fit(X_train[idx], y_train[idx], nb_epoch=3, batch_size=128, verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test,batch_size=256)\n",
    "preds = np.argmax(predictions,axis=1)\n",
    "test_df[\"Sentiment\"] = pd.Series(preds,index=test_df.index)\n",
    "header = [\"PhraseId\", \"Sentiment\"]\n",
    "test_df.to_csv('rotten/predictions.csv', columns = header,index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
